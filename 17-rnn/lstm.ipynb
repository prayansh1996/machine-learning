{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import asarray as npa\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from string import ascii_lowercase\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = open('sherlock.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = ds.read()\n",
    "d = d[:10000]\n",
    "data = re.sub('[^A-Za-z]',' ', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "data = data.lower()\n",
    "print len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Find unique values in x\n",
    "#Create a dixtionary and map chars of x to an index\n",
    "dct = list(set(data))\n",
    "#create a reverse dictionary and map indices back to chars\n",
    "revdct = [(j,i) for i,j in enumerate(dct)]\n",
    "revdct = dict(revdct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, 'a': 1, 'c': 2, 'b': 3, 'e': 4, 'd': 5, 'g': 6, 'f': 7, 'i': 8, 'h': 9, 'k': 10, 'j': 11, 'm': 12, 'l': 13, 'o': 14, 'n': 15, 'q': 16, 'p': 17, 's': 18, 'r': 19, 'u': 20, 't': 21, 'w': 22, 'v': 23, 'y': 24, 'x': 25, 'z': 26}\n"
     ]
    }
   ],
   "source": [
    "print revdct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputSize = len(data)\n",
    "blockSize = 100\n",
    "max_features = 27\n",
    "rowSize = inputSize/blockSize\n",
    "xt = np.zeros((rowSize, blockSize, 27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(rowSize):\n",
    "    k = i*25\n",
    "    for j in range(blockSize):\n",
    "        xt[i,j,revdct[data[k+j]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yt = np.copy(xt)\n",
    "\n",
    "x = np.roll(yt, 1, axis=1)\n",
    "x[:, 0, :] = 0\n",
    "x[:, 0, 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_10 (LSTM)                   (None, 100, 256)      290816      lstm_input_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                   (None, 100, 256)      525312      lstm_10[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_12 (LSTM)                   (None, 100, 256)      525312      lstm_11[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 100, 27)       6939        lstm_12[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 100, 27)       0           dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1,348,379\n",
      "Trainable params: 1,348,379\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, return_sequences=True, input_shape=(blockSize,  max_features)))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dense(max_features))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 3s - loss: 3.0152     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 2s - loss: 2.9703     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 3s - loss: 2.3586     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 3s - loss: 2.2945     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 3s - loss: 2.2393     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 3s - loss: 2.2405     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 3s - loss: 2.2259     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 3s - loss: 2.2057     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 3s - loss: 2.2053     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 3s - loss: 2.2364     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x, yt, batch_size=64, nb_epoch=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lledzt  e ', 'giy g  gtm', 'gskk  k hl', 'xd c et  n', 'nlgafri vc', 'oqfrazdca ', 'dyxkzy d n', 'zjayb odt ', 'xprtvvqrtl', 'tmxtu uo  ', 'lmqga     ', 'ajvazrdcea', 'dukiri p o', 'fywncu   o', 'tg cijtn  ', 'ankqeegnn ', 'xhseuuohi ', 'qrycyvyiv ', 's xlvgvp p', ' pllznt s ', 'luedyf gte', 'inkwdn a  ', 'oqjqgue   ', 'pu jl  ie ', 'aezi tdoe ', 'cfabub s  ', 'gqd i e tt', 'p vvnj aau', ' g irt  v ', 'esjrnutdce', 'zgzvukxe e', 'wpve slmnk', 'kzkfyy  a ', 'cazvdh ot ', 'wm edh led', 'cbkuitn  e', 'vqnoccta  ', 'jutvfssa n', 'yonoa dirs', 'nnruitdo n', 'hbc n  ee ', 'qgwh e tur', 'kbgct  nee', 's ddve vu ', 'gxkfiru cu', 'lv tyizoen', 'azqc hn   ', 'hirh  zts ', 'vnnr e mhn', 'uwjce  ay ', 'mxeis  eet', 'prvk ensfh', 'wcuoa  ct ', ' yoc  c h ', 'ebiwuth bi', 'wolxgcsoi ', 'dkmk tore ', 'msy fmas  ', 'talo  a  s', 'luvo gia h', 'xhrx a d l', 'f yzltut  ', 'pbcddd  pi', 'gksvcoano ', 'cjsv evrbb', 'jdwvw ysto', 'ljafata tk', 'oto eqkets', 'auhgmchgi ', 'cdkalbz xe', 'ivuveri  c', 'lira s k  ', 'ayad q  ft', 'thloxwedx ', 'hpayvhs f ', 'anxowdeo e', 'yj csat i ', 'rqyrx oeab', 'kadune qe ', 'amy utx jg', 'kvuc fgy y', 'u utg   h ', 'iafakan  t', 'mkuzac ee ', 'bxb vthv  ', 'cjcjxuser ', ' odhy nsdu', 'olqixnc   ', 'grmeu d ae', 'dwnqhe rrh', 'st odv   o', 'qvprurj  t', 'ihtxic  oe', ' gopnhy rt', 'sqtweh   e', 'v kz  c ft', 'yi n r h  ', ' nki nat  ', 'baff cltf ', 'fsxtuld n ', 'gocnxiiebi', 'zz lfr bed', 'gdvjoythc ', 'f bcm  e i', 'vjl oopfe ', 'hphgveol d', 'lj utipnd ', 'h agdsc e ', 'ukoavaetcf', 'uqpcylti r', 'jvtrs ennt', 'oyb ntfa r', 'qyrrhyise ', 'kjaaw   h ', 'quote  t  ', 'b hoaeeenv', 'hsc  dizt ', 'wa cfame e', 'atysf ete ', 'uyaelbe s ', 'ol lrgi   ', 'tucxeandce', 'gkag    et', 'yk dzw o  ', 'tj wgv r d', 'vxdamic e ', ' ymvx r  h', 'ymowb dse ']\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "def mnrnd(probs):\n",
    "    rnd = numpy.random.random()\n",
    "    for i in xrange(len(probs)):\n",
    "        rnd -= probs[i]\n",
    "        if rnd <= 0:\n",
    "            return i\n",
    "    return i\n",
    "\n",
    "sentences = numpy.zeros((128, blockSize, max_features))\n",
    "sentences[:, 0, 0] = 1\n",
    "\n",
    "# Start sampling char-sequences. At each iteration i the probability over\n",
    "# the i-th character of each sequences is computed. \n",
    "for i in numpy.arange(10):\n",
    "    probs = model.predict_proba(sentences, verbose=2)[:,i,:]\n",
    "    # Go over each sequence and sample the i-th character.\n",
    "    for j in numpy.arange(len(sentences)):\n",
    "        sentences[j, i+1, mnrnd(probs[j, :])] = 1\n",
    "sentences = [sentence[1:].nonzero()[1] for sentence in sentences]\n",
    "\n",
    "# Convert to readable text.\n",
    "text = []\n",
    "for sentence in sentences:\n",
    "    text.append(''.join([dct[word] for word in sentence]))\n",
    "    \n",
    "print text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
